## Name : 111550126金以凡

### Basic Challenge
| Throughputs (Tokens/sec) | CPU      | GPU      | 
| --------                 | -------- | -------- | 
| tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf  | 11.21     | 105.07     |


### Medium Challenge
| Throughputs (Tokens/sec) | CPU      | GPU      | 
| --------                 | -------- | -------- | 
| tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf  | 10.23     | 105.30     |
| TinyLlama-1.1B-Chat-v1.0-f16  | 4.76     | 72.25     |



### Advance Challenge
| Throughputs (Tokens/sec) | CPU      | GPU      | 
| --------                 | -------- | -------- | 
| tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf  | XXXX     | XXXX     |
| TinyLlama-1.1B-Chat-v1.0-f16  | XXXX     | XXXX     |
| TinyLlama-1.1B-Chat-v1.0-Q8  | XXXX     | XXXX     |


### Advance Challenge

| Throughputs (Tokens/sec) | Accuracy  |
| --------                 | --------  |
| tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf | x/10     |
| TinyLlama-1.1B-Chat-v1.0-f16         | x/10     |
| TinyLlama-1.1B-Chat-v1.0-Q8          | x/10     |

### Questions
* What problems you encountered? How you solve it?
* What you observed between CPU / GPU performance ?    
* Will quantization or smaller-parameters model impact model accuracy or inference throughput ? If so , what's the variation?



